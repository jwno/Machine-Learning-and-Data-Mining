{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have combined all the code lines I said should be at the begining of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing mltools\n",
    "First you want to make sure that mltools sits in the same folder as your notebook (or alternatively wherever your PYTHON_PATH directs).\n",
    "\n",
    "You can see that I have that folder in my directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since mltools is in the right place, I can just import it normally to use it in the HW assignement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mltools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-369eceb04dd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmltools\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mml\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# If this prints error you either defined the PYTHON_PATH to point to somewhere else or entered a different directory.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mltools'"
     ]
    }
   ],
   "source": [
    "import mltools as ml\n",
    "# If this prints error you either defined the PYTHON_PATH to point to somewhere else or entered a different directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using mltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_file = 'data/iris.txt'\n",
    "iris = np.genfromtxt(path_to_file, delimiter=None) # Loading the text data file\n",
    "X = iris[:, :-1]   # Features are the first 4 columns\n",
    "Y = iris[:, -1]    # Classes are the last column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important tool that you will use ALL the time is the shuffle and split data methods. The shuffle is used to randomize the order of points. We generally do not want our data sorted in any meaningful way as this can bias our results.\n",
    "\n",
    "The split allows you to create train and test/validation data easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = ml.shuffleData(X, Y) ## MAKE SURE YOU HAVE BOTH X AND Y!!! (Why?)\n",
    "\n",
    "# It's still the same size, just different order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr, Xva, Ytr, Yva = ml.splitData(X, Y, 0.75)   # Splitting keeping 75% as training and the rest as validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common mistake here is to split and then forget to use the new splitted data and use X, Y instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier\n",
    "\n",
    "You can read about it on the [wiki page](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) or in your notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating an classifier.\n",
    "knn = ml.knn.knnClassify()\n",
    "\n",
    "# Training the classifier.\n",
    "knn.train(Xtr, Ytr, K=5)  # What is this thing doing? (Look at the code)\n",
    "\n",
    "# Making predictions\n",
    "YvaHat = knn.predict(Xva)\n",
    "print YvaHat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A VERY good practice thing you should do after you make predictions is to make sure all the dimensions match. That way you at least know that you probably ran it on the right data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the error rate of our classifier using the 'err' method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.err(Xva, Yva)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the classifier and predictions\n",
    "\n",
    "This is useful if you have 2D data (or 1D for that matter). To show how it works we'll repeat the process  using only the first two columns of X. \n",
    "\n",
    "We plot the areas of classification and the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = ml.knn.knnClassify()\n",
    "knn.train(Xtr[:, :2], Ytr, K=5)\n",
    "\n",
    "ml.plotClassify2D(knn, Xtr[:, :2], Ytr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the test data with the predicted class. Notice that to do so I just had to change the set of points and classes that I give the plotClassify2D method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YvaHat = knn.predict(Xva[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.plotClassify2D(knn, Xva[:, :2], YvaHat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above we plotted the test data with the predicted class. That's why it looks perfectly correct. Next we'll plot the test data with the true class. \n",
    "\n",
    "Now we can see some mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.plotClassify2D(knn, Xva[:, :2], Yva)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Error\n",
    "\n",
    "In the HW assignment you are required to plot the error for the training and validation using the semilogx method. To show you how to do that, I'll use a random errors.\n",
    "\n",
    "In my plotting I will use a more commonly used way of plotting using the axis handler. This way gives a lot more control though I will not demonstrate that too much here. I will try to do add new plotting stuff every new discussion as producing nice plots is 80% of the job for a data scientist :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = [1, 2, 5, 10, 50, 100, 200]\n",
    "train_err = np.random.rand(7)\n",
    "val_err = np.random.rand(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating subplots with just one subplot so basically a single figure.\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "# I added lw (line width) and the label. \n",
    "ax.semilogx(K, train_err, 'r-', lw=3, label='Training')\n",
    "ax.semilogx(K, val_err, 'g-', lw=3, label='Validation')\n",
    "\n",
    "# Adding a legend to the plot that will use the labels from the 'label'.\n",
    "ax.legend()\n",
    "\n",
    "# Controlling the axis.\n",
    "ax.set_xlim(0, 200)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# And still doing this to clean the canvas.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remeber that this was just an example with random number, you won't be able to deduce anything from this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
